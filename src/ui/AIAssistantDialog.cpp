#include "ui/AIAssistantDialog.h"
#include <QScrollArea>
#include <QGroupBox>
#include <QFont>
#include <QFontMetrics>
#include <QSizePolicy>

AIAssistantDialog::AIAssistantDialog(QWidget *parent)
    : QDialog(parent)
{
    setWindowTitle("üßô Assistant IA - Guide des R√©seaux de Neurones");
    setMinimumSize(900, 700);
    resize(1000, 750);
    
    setupUI();
    initializeKnowledgeBase();
    displayWelcomeMessage();
}

AIAssistantDialog::~AIAssistantDialog() {
}

void AIAssistantDialog::setupUI() {
    mainLayout_ = new QVBoxLayout(this);
    mainLayout_->setSpacing(15);
    mainLayout_->setContentsMargins(20, 20, 20, 20);
    
    // En-t√™te avec message de bienvenue
    QGroupBox* headerBox = new QGroupBox;
    QVBoxLayout* headerLayout = new QVBoxLayout(headerBox);
    headerLayout->setContentsMargins(15, 15, 15, 15);
    
    welcomeLabel_ = new QLabel;
    welcomeLabel_->setWordWrap(true);
    welcomeLabel_->setStyleSheet(
        "QLabel { "
        "font-size: 14pt; "
        "font-weight: bold; "
        "color: #2196F3; "
        "padding: 10px; "
        "background-color: #E3F2FD; "
        "border-radius: 8px; "
        "}"
    );
    headerLayout->addWidget(welcomeLabel_);
    mainLayout_->addWidget(headerBox);
    
    // Layout horizontal pour le contenu principal
    contentLayout_ = new QHBoxLayout;
    contentLayout_->setSpacing(15);
    
    // Panneau gauche : Cat√©gories et Questions
    QVBoxLayout* leftLayout = new QVBoxLayout;
    leftLayout->setSpacing(10);
    
    QLabel* categoryLabel = new QLabel("üìö Cat√©gories :");
    categoryLabel->setStyleSheet("font-weight: bold; font-size: 11pt; color: #424242;");
    leftLayout->addWidget(categoryLabel);
    
    categoryList_ = new QListWidget;
    categoryList_->setMaximumWidth(200);
    categoryList_->setStyleSheet(
        "QListWidget { "
        "border: 2px solid #BDBDBD; "
        "border-radius: 5px; "
        "background-color: #FAFAFA; "
        "padding: 5px; "
        "}"
        "QListWidget::item { "
        "padding: 8px; "
        "border-radius: 3px; "
        "margin: 2px; "
        "}"
        "QListWidget::item:selected { "
        "background-color: #2196F3; "
        "color: white; "
        "}"
        "QListWidget::item:hover { "
        "background-color: #E3F2FD; "
        "}"
    );
    leftLayout->addWidget(categoryList_);
    
    QLabel* questionLabel = new QLabel("‚ùì Questions :");
    questionLabel->setStyleSheet("font-weight: bold; font-size: 11pt; color: #424242; margin-top: 10px;");
    leftLayout->addWidget(questionLabel);
    
    questionList_ = new QListWidget;
    questionList_->setStyleSheet(
        "QListWidget { "
        "border: 2px solid #BDBDBD; "
        "border-radius: 5px; "
        "background-color: #FAFAFA; "
        "padding: 5px; "
        "}"
        "QListWidget::item { "
        "padding: 10px; "
        "border-radius: 3px; "
        "margin: 2px; "
        "min-height: 40px; "
        "}"
        "QListWidget::item:selected { "
        "background-color: #4CAF50; "
        "color: white; "
        "}"
        "QListWidget::item:hover { "
        "background-color: #C8E6C9; "
        "}"
    );
    leftLayout->addWidget(questionList_);
    
    contentLayout_->addLayout(leftLayout, 1);
    
    // Panneau droit : R√©ponses
    QVBoxLayout* rightLayout = new QVBoxLayout;
    
    QLabel* answerLabel = new QLabel("üí° R√©ponse d√©taill√©e :");
    answerLabel->setStyleSheet("font-weight: bold; font-size: 11pt; color: #424242;");
    rightLayout->addWidget(answerLabel);
    
    answerDisplay_ = new QTextEdit;
    answerDisplay_->setReadOnly(true);
    answerDisplay_->setStyleSheet(
        "QTextEdit { "
        "border: 2px solid #BDBDBD; "
        "border-radius: 5px; "
        "background-color: #FFFFFF; "
        "padding: 15px; "
        "font-size: 11pt; "
        "line-height: 1.6; "
        "}"
    );
    rightLayout->addWidget(answerDisplay_, 2);
    
    contentLayout_->addLayout(rightLayout, 2);
    
    mainLayout_->addLayout(contentLayout_, 1);
    
    // Bouton de fermeture
    QHBoxLayout* buttonLayout = new QHBoxLayout;
    buttonLayout->addStretch();
    
    closeButton_ = new QPushButton("Fermer");
    closeButton_->setStyleSheet(
        "QPushButton { "
        "background-color: #2196F3; "
        "color: white; "
        "font-weight: bold; "
        "font-size: 11pt; "
        "padding: 10px 30px; "
        "border: none; "
        "border-radius: 5px; "
        "}"
        "QPushButton:hover { "
        "background-color: #1976D2; "
        "}"
        "QPushButton:pressed { "
        "background-color: #0D47A1; "
        "}"
    );
    buttonLayout->addWidget(closeButton_);
    mainLayout_->addLayout(buttonLayout);
    
    // Connexions
    connect(categoryList_, &QListWidget::currentRowChanged, this, &AIAssistantDialog::onCategoryChanged);
    connect(questionList_, &QListWidget::itemClicked, this, &AIAssistantDialog::onQuestionSelected);
    connect(closeButton_, &QPushButton::clicked, this, &QDialog::accept);
}

void AIAssistantDialog::initializeKnowledgeBase() {
    // Cat√©gorie 1: Introduction et Bienvenue
    categories_ << "Introduction" << "Fonctionnement" << "Architecture" << "Dataset" 
                << "Entra√Ænement" << "Param√®tres" << "M√©triques" << "Conseils";
    
    QMap<QString, QString> intro;
    intro["Qu'est-ce qu'un r√©seau de neurones ?"] = 
        "Un r√©seau de neurones est un mod√®le informatique inspir√© du fonctionnement du cerveau humain.\n\n"
        "üîπ **Composants principaux :**\n"
        "‚Ä¢ **Neurones** : Unit√©s de calcul qui re√ßoivent des entr√©es, les traitent et produisent une sortie\n"
        "‚Ä¢ **Connexions** : Liens entre les neurones avec des poids (weights) qui d√©terminent l'importance de chaque connexion\n"
        "‚Ä¢ **Couches** : Groupes de neurones organis√©s en couches (entr√©e, cach√©es, sortie)\n\n"
        "üîπ **Fonctionnement :**\n"
        "Les donn√©es entrent par la couche d'entr√©e, sont trait√©es par les couches cach√©es, et produisent un r√©sultat √† la sortie. "
        "Le r√©seau apprend en ajustant les poids des connexions pendant l'entra√Ænement.\n\n"
        "üîπ **Applications :**\n"
        "Reconnaissance d'images, traitement du langage naturel, pr√©dictions, classification, etc.";
    
    intro["Pourquoi utiliser un r√©seau de neurones ?"] = 
        "Les r√©seaux de neurones sont particuli√®rement utiles pour :\n\n"
        "‚úÖ **Reconnaissance de patterns complexes** : Ils peuvent identifier des motifs que les algorithmes traditionnels ne peuvent pas d√©tecter\n\n"
        "‚úÖ **Apprentissage automatique** : Ils apprennent √† partir d'exemples sans programmation explicite de chaque r√®gle\n\n"
        "‚úÖ **G√©n√©ralisation** : Une fois entra√Æn√©s, ils peuvent traiter de nouvelles donn√©es similaires\n\n"
        "‚úÖ **Tol√©rance au bruit** : Ils peuvent fonctionner m√™me avec des donn√©es imparfaites ou incompl√®tes\n\n"
        "‚úÖ **Non-lin√©arit√©** : Ils peuvent mod√©liser des relations complexes et non-lin√©aires entre les donn√©es";
    
    knowledgeBase_["Introduction"] = intro;
    
    // Cat√©gorie 2: Fonctionnement
    QMap<QString, QString> fonctionnement;
    fonctionnement["Comment fonctionne un r√©seau de neurones ?"] = 
        "Le fonctionnement d'un r√©seau de neurones se d√©roule en plusieurs √©tapes :\n\n"
        "**1. Propagation avant (Forward Propagation) :**\n"
        "   ‚Ä¢ Les donn√©es d'entr√©e sont pr√©sent√©es √† la couche d'entr√©e\n"
        "   ‚Ä¢ Chaque neurone calcule : somme pond√©r√©e des entr√©es √ó poids + biais\n"
        "   ‚Ä¢ Une fonction d'activation transforme cette somme (ex: sigmo√Øde, ReLU)\n"
        "   ‚Ä¢ Le r√©sultat est transmis √† la couche suivante\n"
        "   ‚Ä¢ Ce processus se r√©p√®te jusqu'√† la couche de sortie\n\n"
        "**2. Calcul de l'erreur :**\n"
        "   ‚Ä¢ La sortie du r√©seau est compar√©e √† la valeur attendue\n"
        "   ‚Ä¢ L'erreur est calcul√©e (ex: erreur quadratique moyenne)\n\n"
        "**3. R√©tropropagation (Backpropagation) :**\n"
        "   ‚Ä¢ L'erreur est propag√©e en arri√®re √† travers le r√©seau\n"
        "   ‚Ä¢ Les poids sont ajust√©s pour r√©duire l'erreur\n"
        "   ‚Ä¢ Le taux d'apprentissage d√©termine l'amplitude des ajustements\n\n"
        "**4. R√©p√©tition :**\n"
        "   ‚Ä¢ Ce cycle se r√©p√®te pour chaque √©chantillon d'entra√Ænement\n"
        "   ‚Ä¢ Le r√©seau s'am√©liore progressivement";
    
    fonctionnement["Qu'est-ce qu'une fonction d'activation ?"] = 
        "Une fonction d'activation d√©termine la sortie d'un neurone en fonction de sa somme pond√©r√©e.\n\n"
        "**R√¥le principal :**\n"
        "‚Ä¢ Introduire la non-lin√©arit√© dans le r√©seau\n"
        "‚Ä¢ Permettre au r√©seau d'apprendre des patterns complexes\n"
        "‚Ä¢ Limiter la sortie √† une plage sp√©cifique\n\n"
        "**Types courants :**\n\n"
        "üîπ **Sigmo√Øde** :\n"
        "   ‚Ä¢ Plage : [0, 1]\n"
        "   ‚Ä¢ Utilis√©e pour : classification binaire, couches de sortie\n"
        "   ‚Ä¢ Avantage : sortie lisse et diff√©rentiable\n\n"
        "üîπ **ReLU (Rectified Linear Unit) :**\n"
        "   ‚Ä¢ Plage : [0, +‚àû[\n"
        "   ‚Ä¢ Utilis√©e pour : couches cach√©es\n"
        "   ‚Ä¢ Avantage : calcul rapide, √©vite le probl√®me de gradient qui dispara√Æt\n\n"
        "üîπ **Tanh** :\n"
        "   ‚Ä¢ Plage : [-1, 1]\n"
        "   ‚Ä¢ Utilis√©e pour : normalisation centr√©e\n\n"
        "üîπ **Lin√©aire** :\n"
        "   ‚Ä¢ Pas de transformation\n"
        "   ‚Ä¢ Utilis√©e pour : r√©gression";
    
    fonctionnement["Qu'est-ce que la r√©tropropagation ?"] = 
        "La r√©tropropagation (backpropagation) est l'algorithme d'apprentissage qui permet au r√©seau d'ajuster ses poids.\n\n"
        "**Principe :**\n"
        "1. **Propagation avant** : Calculer la sortie du r√©seau\n"
        "2. **Calcul de l'erreur** : Comparer la sortie avec la valeur attendue\n"
        "3. **Propagation arri√®re** : Propager l'erreur de la sortie vers l'entr√©e\n"
        "4. **Mise √† jour des poids** : Ajuster chaque poids proportionnellement √† sa contribution √† l'erreur\n\n"
        "**Formule de mise √† jour :**\n"
        "Nouveau_poids = Ancien_poids - (Taux_apprentissage √ó Gradient_erreur)\n\n"
        "**Avantages :**\n"
        "‚Ä¢ Efficace pour les r√©seaux multicouches\n"
        "‚Ä¢ Permet d'apprendre des repr√©sentations complexes\n"
        "‚Ä¢ Calcul automatique des gradients\n\n"
        "**Note :** C'est gr√¢ce √† la r√©tropropagation que les r√©seaux de neurones peuvent apprendre efficacement !";
    
    knowledgeBase_["Fonctionnement"] = fonctionnement;
    
    // Cat√©gorie 3: Architecture
    QMap<QString, QString> architecture;
    architecture["Qu'est-ce qu'une couche dans un r√©seau de neurones ?"] = 
        "Une couche est un groupe de neurones qui traitent les donn√©es en parall√®le.\n\n"
        "**Types de couches :**\n\n"
        "üîπ **Couche d'entr√©e (Input Layer) :**\n"
        "   ‚Ä¢ Premi√®re couche du r√©seau\n"
        "   ‚Ä¢ Re√ßoit les donn√©es brutes\n"
        "   ‚Ä¢ Nombre de neurones = nombre de caract√©ristiques d'entr√©e\n"
        "   ‚Ä¢ Exemple : 2 neurones pour 2 entr√©es (X, Y)\n\n"
        "üîπ **Couches cach√©es (Hidden Layers) :**\n"
        "   ‚Ä¢ Couches interm√©diaires entre l'entr√©e et la sortie\n"
        "   ‚Ä¢ Effectuent les transformations complexes\n"
        "   ‚Ä¢ Plus il y a de couches, plus le r√©seau peut apprendre de patterns complexes\n"
        "   ‚Ä¢ Exemple : 2 neurones dans une couche cach√©e\n\n"
        "üîπ **Couche de sortie (Output Layer) :**\n"
        "   ‚Ä¢ Derni√®re couche du r√©seau\n"
        "   ‚Ä¢ Produit le r√©sultat final\n"
        "   ‚Ä¢ Nombre de neurones = nombre de sorties attendues\n"
        "   ‚Ä¢ Exemple : 1 neurone pour une sortie binaire\n\n"
        "**Exemple d'architecture : 2-2-1**\n"
        "   ‚Ä¢ 2 neurones d'entr√©e\n"
        "   ‚Ä¢ 2 neurones dans la couche cach√©e\n"
        "   ‚Ä¢ 1 neurone de sortie";
    
    architecture["Comment choisir l'architecture d'un r√©seau ?"] = 
        "Le choix de l'architecture d√©pend de votre probl√®me et de vos donn√©es.\n\n"
        "**Couche d'entr√©e :**\n"
        "‚Ä¢ Nombre de neurones = nombre de caract√©ristiques dans vos donn√©es\n"
        "‚Ä¢ Exemple : 2 entr√©es (X, Y) ‚Üí 2 neurones\n\n"
        "**Couches cach√©es :**\n"
        "‚Ä¢ **Profondeur** (nombre de couches) :\n"
        "  - Probl√®mes simples : 1-2 couches\n"
        "  - Probl√®mes complexes : 3+ couches (r√©seaux profonds)\n"
        "‚Ä¢ **Largeur** (neurones par couche) :\n"
        "  - Commencez avec 2-3 fois le nombre d'entr√©es\n"
        "  - Ajustez selon les performances\n"
        "  - Trop de neurones ‚Üí surapprentissage\n"
        "  - Trop peu ‚Üí sous-apprentissage\n\n"
        "**Couche de sortie :**\n"
        "‚Ä¢ Classification binaire : 1 neurone\n"
        "‚Ä¢ Classification multi-classes : nombre de classes\n"
        "‚Ä¢ R√©gression : 1 neurone (ou plusieurs pour plusieurs sorties)\n\n"
        "**R√®gles g√©n√©rales :**\n"
        "‚úÖ Commencez simple (ex: 2-2-1 pour XOR)\n"
        "‚úÖ Augmentez progressivement si n√©cessaire\n"
        "‚úÖ Testez diff√©rentes architectures\n"
        "‚úÖ √âvitez les r√©seaux trop complexes pour de petits datasets";
    
    architecture["Qu'est-ce qu'un neurone ?"] = 
        "Un neurone est l'unit√© de base d'un r√©seau de neurones.\n\n"
        "**Structure d'un neurone :**\n\n"
        "1. **Entr√©es (Inputs)** :\n"
        "   ‚Ä¢ Re√ßoit des valeurs des neurones de la couche pr√©c√©dente\n"
        "   ‚Ä¢ Chaque entr√©e a un poids associ√©\n\n"
        "2. **Calcul de la somme pond√©r√©e :**\n"
        "   Somme = (Entr√©e‚ÇÅ √ó Poids‚ÇÅ) + (Entr√©e‚ÇÇ √ó Poids‚ÇÇ) + ... + Biais\n\n"
        "3. **Fonction d'activation :**\n"
        "   Sortie = Activation(Somme)\n"
        "   ‚Ä¢ Transforme la somme en sortie du neurone\n"
        "   ‚Ä¢ Exemples : sigmo√Øde, ReLU, tanh\n\n"
        "4. **Sortie :**\n"
        "   ‚Ä¢ La valeur calcul√©e est transmise aux neurones de la couche suivante\n\n"
        "**Analogie :**\n"
        "Imaginez un neurone comme un petit processeur qui :\n"
        "‚Ä¢ Re√ßoit des signaux (entr√©es)\n"
        "‚Ä¢ Les pond√®re selon leur importance (poids)\n"
        "‚Ä¢ Les combine et les transforme (fonction d'activation)\n"
        "‚Ä¢ Produit un signal de sortie";
    
    knowledgeBase_["Architecture"] = architecture;
    
    // Cat√©gorie 4: Dataset
    QMap<QString, QString> dataset;
    dataset["Qu'est-ce qu'un dataset ?"] = 
        "Un dataset (jeu de donn√©es) est une collection d'exemples utilis√©s pour entra√Æner et tester le r√©seau.\n\n"
        "**Composition :**\n"
        "‚Ä¢ **Entr√©es (Features)** : Les donn√©es que vous donnez au r√©seau\n"
        "‚Ä¢ **Sorties (Labels/Targets)** : Les r√©sultats attendus\n\n"
        "**Format dans NeuroUIT :**\n"
        "Le dataset doit √™tre au format CSV avec :\n"
        "‚Ä¢ Colonnes d'entr√©es suivies de colonnes de sortie\n"
        "‚Ä¢ Exemple : X, Y, R√©sultat\n"
        "‚Ä¢ Chaque ligne = un √©chantillon d'entra√Ænement\n\n"
        "**Exemple de dataset XOR :**\n"
        "0, 0, 0\n"
        "0, 1, 1\n"
        "1, 0, 1\n"
        "1, 1, 0\n\n"
        "Ici : 2 entr√©es (X, Y) et 1 sortie (R√©sultat)\n\n"
        "**Types de datasets :**\n"
        "‚Ä¢ **Classification** : Pr√©dire une cat√©gorie (ex: 0 ou 1)\n"
        "‚Ä¢ **R√©gression** : Pr√©dire une valeur num√©rique continue";
    
    dataset["Comment pr√©parer un dataset ?"] = 
        "La pr√©paration du dataset est cruciale pour un bon apprentissage.\n\n"
        "**√âtapes de pr√©paration :**\n\n"
        "1. **Collecte des donn√©es :**\n"
        "   ‚Ä¢ Rassemblez suffisamment d'exemples\n"
        "   ‚Ä¢ Assurez-vous que les donn√©es sont repr√©sentatives\n\n"
        "2. **Format CSV :**\n"
        "   ‚Ä¢ Format : Entr√©e1, Entr√©e2, ..., Sortie1, Sortie2, ...\n"
        "   ‚Ä¢ Pas d'en-t√™te (ou cochez 'Avec en-t√™te' si pr√©sent)\n"
        "   ‚Ä¢ S√©parateur : virgule\n\n"
        "3. **Normalisation (optionnel mais recommand√©) :**\n"
        "   ‚Ä¢ Mettez les valeurs sur une √©chelle similaire\n"
        "   ‚Ä¢ Exemple : [0, 1] ou [-1, 1]\n"
        "   ‚Ä¢ Am√©liore la convergence de l'apprentissage\n\n"
        "4. **Division des donn√©es :**\n"
        "   ‚Ä¢ Entra√Ænement : 70-80% des donn√©es\n"
        "   ‚Ä¢ Test : 20-30% des donn√©es\n\n"
        "**Conseils :**\n"
        "‚úÖ Plus de donn√©es = g√©n√©ralement meilleur\n"
        "‚úÖ √âvitez les donn√©es bruit√©es ou erron√©es\n"
        "‚úÖ Assurez-vous que les entr√©es et sorties correspondent";
    
    dataset["Quels datasets sont fournis avec NeuroUIT ?"] = 
        "NeuroUIT inclut plusieurs datasets d'exemple pour vous aider √† d√©marrer :\n\n"
        "**Datasets de classification :**\n"
        "‚Ä¢ **XOR_dataset.csv** : Porte logique XOR (2 entr√©es, 1 sortie)\n"
        "‚Ä¢ **AND_dataset.csv** : Porte logique AND\n"
        "‚Ä¢ **OR_dataset.csv** : Porte logique OR\n"
        "‚Ä¢ **binary_classification.csv** : Classification binaire g√©n√©rale\n\n"
        "**Datasets de r√©gression :**\n"
        "‚Ä¢ **linear_regression.csv** : R√©gression lin√©aire simple\n"
        "‚Ä¢ **sine_wave.csv** : Approximation de fonction sinuso√Ødale\n\n"
        "**Recommandations :**\n"
        "üéØ **Pour d√©buter** : Commencez avec XOR_dataset.csv\n"
        "   ‚Ä¢ Architecture recommand√©e : 2-2-1\n"
        "   ‚Ä¢ Simple √† comprendre et visualiser\n\n"
        "üéØ **Pour tester** : Essayez binary_classification.csv\n"
        "   ‚Ä¢ Plus complexe que XOR\n"
        "   ‚Ä¢ Bon pour tester diff√©rentes architectures";
    
    knowledgeBase_["Dataset"] = dataset;
    
    // Cat√©gorie 5: Entra√Ænement
    QMap<QString, QString> entrainement;
    entrainement["Qu'est-ce que l'entra√Ænement d'un r√©seau ?"] = 
        "L'entra√Ænement est le processus par lequel le r√©seau apprend √† r√©soudre un probl√®me.\n\n"
        "**Processus d'entra√Ænement :**\n\n"
        "1. **Initialisation :**\n"
        "   ‚Ä¢ Les poids sont initialis√©s al√©atoirement (petites valeurs)\n"
        "   ‚Ä¢ Les biais sont g√©n√©ralement initialis√©s √† 0\n\n"
        "2. **It√©ration sur les √©chantillons :**\n"
        "   Pour chaque √©chantillon du dataset :\n"
        "   a) Propagation avant : calculer la sortie\n"
        "   b) Calculer l'erreur\n"
        "   c) R√©tropropagation : ajuster les poids\n\n"
        "3. **√âpoques :**\n"
        "   ‚Ä¢ Une √©poque = un passage complet sur tout le dataset\n"
        "   ‚Ä¢ Le r√©seau s'am√©liore √† chaque √©poque\n"
        "   ‚Ä¢ G√©n√©ralement, plusieurs √©poques sont n√©cessaires\n\n"
        "4. **Arr√™t :**\n"
        "   ‚Ä¢ Quand l'erreur est suffisamment faible\n"
        "   ‚Ä¢ Ou apr√®s un nombre d'√©poques d√©fini\n"
        "   ‚Ä¢ Ou si l'erreur ne diminue plus (convergence)\n\n"
        "**Objectif :**\n"
        "Trouver les poids optimaux qui minimisent l'erreur entre les pr√©dictions et les valeurs r√©elles.";
    
    entrainement["Qu'est-ce qu'une √©poque (epoch) ?"] = 
        "Une √©poque (epoch) est un cycle complet d'entra√Ænement sur tout le dataset.\n\n"
        "**D√©finition :**\n"
        "‚Ä¢ Le r√©seau voit tous les √©chantillons d'entra√Ænement une fois\n"
        "‚Ä¢ Les poids sont mis √† jour pour chaque √©chantillon\n"
        "‚Ä¢ L'erreur moyenne est calcul√©e √† la fin de l'√©poque\n\n"
        "**Exemple :**\n"
        "Si vous avez 100 √©chantillons et 50 √©poques :\n"
        "‚Ä¢ Le r√©seau verra chaque √©chantillon 50 fois\n"
        "‚Ä¢ Total : 5000 it√©rations d'apprentissage\n\n"
        "**Nombre d'√©poques :**\n"
        "‚Ä¢ **Trop peu** : Le r√©seau n'apprend pas suffisamment\n"
        "‚Ä¢ **Trop beaucoup** : Risque de surapprentissage (overfitting)\n"
        "‚Ä¢ **Recommandation** : Commencez avec 100-500 √©poques\n\n"
        "**Observation :**\n"
        "Regardez la courbe d'erreur :\n"
        "‚Ä¢ Si elle diminue encore ‚Üí continuez\n"
        "‚Ä¢ Si elle stagne ‚Üí arr√™tez ou ajustez les param√®tres";
    
    entrainement["Qu'est-ce que le surapprentissage (overfitting) ?"] = 
        "Le surapprentissage se produit quand le r√©seau m√©morise les donn√©es d'entra√Ænement au lieu d'apprendre √† g√©n√©raliser.\n\n"
        "**Sympt√¥mes :**\n"
        "‚Ä¢ Erreur d'entra√Ænement tr√®s faible\n"
        "‚Ä¢ Erreur de test √©lev√©e\n"
        "‚Ä¢ Le r√©seau fonctionne bien sur les donn√©es vues, mal sur les nouvelles\n\n"
        "**Causes :**\n"
        "‚Ä¢ R√©seau trop complexe pour la quantit√© de donn√©es\n"
        "‚Ä¢ Trop d'√©poques d'entra√Ænement\n"
        "‚Ä¢ Dataset trop petit\n\n"
        "**Solutions :**\n"
        "‚úÖ R√©duire la complexit√© du r√©seau (moins de neurones/couches)\n"
        "‚úÖ Augmenter la taille du dataset\n"
        "‚úÖ Arr√™ter l'entra√Ænement plus t√¥t (early stopping)\n"
        "‚úÖ Utiliser la r√©gularisation\n"
        "‚úÖ Augmenter le batch size\n\n"
        "**Comment d√©tecter :**\n"
        "Comparez l'erreur d'entra√Ænement et l'erreur de test. Si l'√©cart est grand, c'est probablement du surapprentissage.";
    
    knowledgeBase_["Entra√Ænement"] = entrainement;
    
    // Cat√©gorie 6: Param√®tres
    QMap<QString, QString> parametres;
    parametres["Qu'est-ce que le taux d'apprentissage (learning rate) ?"] = 
        "Le taux d'apprentissage contr√¥le la vitesse √† laquelle le r√©seau apprend.\n\n"
        "**D√©finition :**\n"
        "C'est un facteur qui d√©termine l'amplitude des ajustements des poids √† chaque √©tape d'apprentissage.\n\n"
        "**Valeurs typiques :**\n"
        "‚Ä¢ **Petit (0.001 - 0.01)** : Apprentissage lent mais stable\n"
        "‚Ä¢ **Moyen (0.01 - 0.1)** : Bon compromis (recommand√© pour d√©buter)\n"
        "‚Ä¢ **Grand (> 0.1)** : Apprentissage rapide mais peut √™tre instable\n\n"
        "**Effets :**\n\n"
        "üîπ **Taux trop petit :**\n"
        "   ‚Ä¢ Apprentissage tr√®s lent\n"
        "   ‚Ä¢ Peut rester bloqu√© dans un minimum local\n"
        "   ‚Ä¢ N√©cessite beaucoup d'√©poques\n\n"
        "üîπ **Taux trop grand :**\n"
        "   ‚Ä¢ Apprentissage instable\n"
        "   ‚Ä¢ L'erreur peut osciller ou augmenter\n"
        "   ‚Ä¢ Peut ne pas converger\n\n"
        "üîπ **Taux optimal :**\n"
        "   ‚Ä¢ L'erreur diminue r√©guli√®rement\n"
        "   ‚Ä¢ Convergence stable\n"
        "   ‚Ä¢ Bon √©quilibre vitesse/stabilit√©\n\n"
        "**Recommandation :**\n"
        "Commencez avec 0.01 et ajustez selon les r√©sultats. Observez la courbe d'erreur pour trouver le bon taux.";
    
    parametres["Qu'est-ce que le batch size ?"] = 
        "Le batch size est le nombre d'√©chantillons trait√©s avant de mettre √† jour les poids.\n\n"
        "**Modes d'entra√Ænement :**\n\n"
        "üîπ **Batch size = 1 (Online Learning) :**\n"
        "   ‚Ä¢ Mise √† jour apr√®s chaque √©chantillon\n"
        "   ‚Ä¢ Plus de mises √† jour, apprentissage plus rapide\n"
        "   ‚Ä¢ Peut √™tre plus instable\n"
        "   ‚Ä¢ Bon pour les petits datasets\n\n"
        "üîπ **Batch size = N (Mini-batch) :**\n"
        "   ‚Ä¢ Mise √† jour apr√®s N √©chantillons\n"
        "   ‚Ä¢ Plus stable, moyenne des gradients\n"
        "   ‚Ä¢ Bon compromis\n"
        "   ‚Ä¢ Recommand√© pour la plupart des cas\n\n"
        "üîπ **Batch size = Taille du dataset (Full batch) :**\n"
        "   ‚Ä¢ Mise √† jour apr√®s avoir vu tout le dataset\n"
        "   ‚Ä¢ Tr√®s stable mais lent\n"
        "   ‚Ä¢ N√©cessite beaucoup de m√©moire\n\n"
        "**Recommandation :**\n"
        "Pour d√©buter, utilisez batch size = 1 (comme dans les exemples XOR). "
        "Pour des datasets plus grands, essayez 8, 16, ou 32.";
    
    parametres["Qu'est-ce que le momentum ?"] = 
        "Le momentum aide le r√©seau √† converger plus rapidement en conservant une partie de la direction pr√©c√©dente.\n\n"
        "**Principe :**\n"
        "Au lieu de se d√©placer uniquement selon le gradient actuel, le r√©seau conserve une \"inertie\" des mises √† jour pr√©c√©dentes.\n\n"
        "**Avantages :**\n"
        "‚úÖ Convergence plus rapide\n"
        "‚úÖ Aide √† √©chapper aux minima locaux\n"
        "‚úÖ R√©duit les oscillations\n"
        "‚úÖ Am√©liore la stabilit√© de l'apprentissage\n\n"
        "**Valeurs typiques :**\n"
        "‚Ä¢ **0.0** : Pas de momentum (d√©sactiv√©)\n"
        "‚Ä¢ **0.5 - 0.9** : Momentum mod√©r√© √† fort\n"
        "‚Ä¢ **0.9** : Valeur couramment utilis√©e\n\n"
        "**Quand l'utiliser :**\n"
        "‚Ä¢ Pour acc√©l√©rer l'apprentissage\n"
        "‚Ä¢ Quand l'apprentissage oscille\n"
        "‚Ä¢ Pour des probl√®mes complexes\n\n"
        "**Note :**\n"
        "Pour d√©buter, vous pouvez laisser le momentum √† 0. Activez-le si l'apprentissage est trop lent ou instable.";
    
    parametres["Qu'est-ce que le m√©lange (shuffle) ?"] = 
        "Le m√©lange (shuffle) r√©organise al√©atoirement l'ordre des √©chantillons √† chaque √©poque.\n\n"
        "**Pourquoi c'est important :**\n\n"
        "‚úÖ **√âvite le biais d'ordre :**\n"
        "   ‚Ä¢ Sans shuffle, le r√©seau peut apprendre l'ordre des donn√©es plut√¥t que les patterns\n"
        "   ‚Ä¢ Le m√©lange force le r√©seau √† apprendre les vraies relations\n\n"
        "‚úÖ **Am√©liore la g√©n√©ralisation :**\n"
        "   ‚Ä¢ Le r√©seau voit les donn√©es dans diff√©rents contextes\n"
        "   ‚Ä¢ Meilleure capacit√© √† g√©n√©raliser\n\n"
        "‚úÖ **Convergence plus stable :**\n"
        "   ‚Ä¢ R√©duit les oscillations dans l'apprentissage\n"
        "   ‚Ä¢ Courbe d'erreur plus lisse\n\n"
        "**Recommandation :**\n"
        "Activez toujours le shuffle (Oui) sauf si vous avez une raison sp√©cifique de le d√©sactiver. "
        "C'est une bonne pratique standard en apprentissage automatique.";
    
    knowledgeBase_["Param√®tres"] = parametres;
    
    // Cat√©gorie 7: M√©triques
    QMap<QString, QString> metriques;
    metriques["Quelles m√©triques sont utilis√©es pour √©valuer un r√©seau ?"] = 
        "Plusieurs m√©triques permettent d'√©valuer la performance d'un r√©seau de neurones.\n\n"
        "**Pour la Classification :**\n\n"
        "üîπ **Pr√©cision (Accuracy) :**\n"
        "   ‚Ä¢ Pourcentage de pr√©dictions correctes\n"
        "   ‚Ä¢ Formule : (Pr√©dictions correctes) / (Total)\n"
        "   ‚Ä¢ Exemple : 90% = 90 pr√©dictions correctes sur 100\n\n"
        "üîπ **Pr√©cision (Precision) :**\n"
        "   ‚Ä¢ Pour les pr√©dictions positives, combien sont vraiment positives\n"
        "   ‚Ä¢ Formule : Vrais Positifs / (Vrais Positifs + Faux Positifs)\n\n"
        "üîπ **Rappel (Recall) :**\n"
        "   ‚Ä¢ Parmi les vrais positifs, combien sont d√©tect√©s\n"
        "   ‚Ä¢ Formule : Vrais Positifs / (Vrais Positifs + Faux N√©gatifs)\n\n"
        "üîπ **Score F1 :**\n"
        "   ‚Ä¢ Moyenne harmonique de pr√©cision et rappel\n"
        "   ‚Ä¢ Bonne mesure d'√©quilibre\n"
        "   ‚Ä¢ Formule : 2 √ó (Pr√©cision √ó Rappel) / (Pr√©cision + Rappel)\n\n"
        "**Pour la R√©gression :**\n\n"
        "üîπ **MSE (Erreur Quadratique Moyenne) :**\n"
        "   ‚Ä¢ Mesure l'erreur moyenne au carr√©\n"
        "   ‚Ä¢ Plus petit = mieux\n\n"
        "üîπ **MAE (Erreur Absolue Moyenne) :**\n"
        "   ‚Ä¢ Erreur moyenne en valeur absolue\n"
        "   ‚Ä¢ Plus facile √† interpr√©ter que MSE\n\n"
        "üîπ **R¬≤ (Coefficient de D√©termination) :**\n"
        "   ‚Ä¢ Mesure la qualit√© de l'ajustement\n"
        "   ‚Ä¢ Plage : 0 √† 1 (1 = parfait)";
    
    metriques["Comment interpr√©ter la courbe d'erreur ?"] = 
        "La courbe d'erreur montre l'√©volution de l'erreur pendant l'entra√Ænement.\n\n"
        "**Courbes typiques :**\n\n"
        "üìâ **Courbe d√©croissante r√©guli√®re :**\n"
        "   ‚Ä¢ ‚úÖ Bon signe ! Le r√©seau apprend correctement\n"
        "   ‚Ä¢ L'erreur diminue progressivement\n"
        "   ‚Ä¢ Continuez l'entra√Ænement\n\n"
        "üìä **Courbe qui stagne :**\n"
        "   ‚Ä¢ Le r√©seau a atteint sa limite\n"
        "   ‚Ä¢ Solutions : augmenter le taux d'apprentissage, changer l'architecture, ou arr√™ter\n\n"
        "üìà **Courbe qui augmente :**\n"
        "   ‚Ä¢ ‚ö†Ô∏è Probl√®me ! Taux d'apprentissage trop √©lev√©\n"
        "   ‚Ä¢ R√©duisez le taux d'apprentissage\n\n"
        "üåä **Courbe oscillante :**\n"
        "   ‚Ä¢ Taux d'apprentissage trop √©lev√© ou batch size trop petit\n"
        "   ‚Ä¢ R√©duisez le taux d'apprentissage ou augmentez le batch size\n\n"
        "**Objectif :**\n"
        "Une courbe qui descend r√©guli√®rement vers une valeur faible et stable indique un bon apprentissage.";
    
    metriques["Qu'est-ce qu'une matrice de confusion ?"] = 
        "La matrice de confusion est un tableau qui montre la performance d'un mod√®le de classification.\n\n"
        "**Structure :**\n"
        "Pr√©dit / R√©el     Classe 0    Classe 1\n"
        "Classe 0          VN          FP\n"
        "Classe 1          FN          VP\n\n"
        "**Terminologie :**\n\n"
        "üîπ **VP (Vrais Positifs)** : Correctement pr√©dit comme positif\n"
        "üîπ **VN (Vrais N√©gatifs)** : Correctement pr√©dit comme n√©gatif\n"
        "üîπ **FP (Faux Positifs)** : Incorrectement pr√©dit comme positif\n"
        "üîπ **FN (Faux N√©gatifs)** : Incorrectement pr√©dit comme n√©gatif\n\n"
        "**Interpr√©tation :**\n"
        "‚Ä¢ **Diagonale principale** : Pr√©dictions correctes\n"
        "‚Ä¢ **Hors diagonale** : Erreurs de classification\n\n"
        "**Exemple :**\n"
        "Si vous avez 100 √©chantillons :\n"
        "‚Ä¢ 80 VP + 15 VN = 95 corrects\n"
        "‚Ä¢ 3 FP + 2 FN = 5 erreurs\n"
        "‚Ä¢ Pr√©cision = 95%\n\n"
        "**Utilit√© :**\n"
        "Permet d'identifier quels types d'erreurs le mod√®le fait le plus souvent.";
    
    knowledgeBase_["M√©triques"] = metriques;
    
    // Cat√©gorie 8: Conseils
    QMap<QString, QString> conseils;
    conseils["Comment bien d√©buter avec NeuroUIT ?"] = 
        "Voici un guide pas √† pas pour bien commencer :\n\n"
        "**√âtape 1 : Cr√©er un r√©seau simple**\n"
        "   ‚Ä¢ Cliquez sur 'Nouveau r√©seau'\n"
        "   ‚Ä¢ Architecture recommand√©e : 2-2-1\n"
        "   ‚Ä¢ Fonction d'activation : Sigmo√Øde pour les deux couches\n\n"
        "**√âtape 2 : Charger un dataset d'exemple**\n"
        "   ‚Ä¢ Cliquez sur 'Charger dataset'\n"
        "   ‚Ä¢ S√©lectionnez 'XOR_dataset.csv'\n"
        "   ‚Ä¢ Configurez : 2 entr√©es, 1 sortie, pas d'en-t√™te\n\n"
        "**√âtape 3 : Configurer l'entra√Ænement**\n"
        "   ‚Ä¢ Taux d'apprentissage : 0.01\n"
        "   ‚Ä¢ √âpoques : 100\n"
        "   ‚Ä¢ Batch size : 1\n"
        "   ‚Ä¢ Momentum : 0\n"
        "   ‚Ä¢ M√©langer : Oui\n\n"
        "**√âtape 4 : Lancer l'entra√Ænement**\n"
        "   ‚Ä¢ Cliquez sur 'Lancer'\n"
        "   ‚Ä¢ Observez la courbe d'erreur qui diminue\n"
        "   ‚Ä¢ Attendez la fin de l'entra√Ænement\n\n"
        "**√âtape 5 : Tester le r√©seau**\n"
        "   ‚Ä¢ Cliquez sur 'Tester'\n"
        "   ‚Ä¢ Consultez les m√©triques et r√©sultats\n"
        "   ‚Ä¢ V√©rifiez la matrice de confusion\n\n"
        "**Conseils :**\n"
        "‚úÖ Commencez simple, complexifiez progressivement\n"
        "‚úÖ Observez toujours la courbe d'erreur\n"
        "‚úÖ Testez diff√©rentes configurations\n"
        "‚úÖ Utilisez l'assistant IA pour comprendre les concepts";
    
    conseils["Quels sont les probl√®mes courants et leurs solutions ?"] = 
        "Voici les probl√®mes fr√©quents et comment les r√©soudre :\n\n"
        "**Probl√®me 1 : L'erreur ne diminue pas**\n"
        "üîß Solutions :\n"
        "   ‚Ä¢ Augmentez le taux d'apprentissage (essayez 0.1)\n"
        "   ‚Ä¢ V√©rifiez que le dataset est correct\n"
        "   ‚Ä¢ Augmentez le nombre d'√©poques\n"
        "   ‚Ä¢ V√©rifiez l'architecture (assez de neurones ?)\n\n"
        "**Probl√®me 2 : L'erreur oscille**\n"
        "üîß Solutions :\n"
        "   ‚Ä¢ R√©duisez le taux d'apprentissage\n"
        "   ‚Ä¢ Augmentez le batch size\n"
        "   ‚Ä¢ Activez le momentum (0.5-0.9)\n\n"
        "**Probl√®me 3 : Pr√©cision faible**\n"
        "üîß Solutions :\n"
        "   ‚Ä¢ Augmentez le nombre de neurones/couches\n"
        "   ‚Ä¢ Entra√Ænez plus longtemps\n"
        "   ‚Ä¢ V√©rifiez la qualit√© du dataset\n"
        "   ‚Ä¢ Essayez diff√©rentes fonctions d'activation\n\n"
        "**Probl√®me 4 : Surapprentissage**\n"
        "üîß Solutions :\n"
        "   ‚Ä¢ R√©duisez la complexit√© du r√©seau\n"
        "   ‚Ä¢ Augmentez la taille du dataset\n"
        "   ‚Ä¢ Arr√™tez l'entra√Ænement plus t√¥t\n\n"
        "**Probl√®me 5 : Le r√©seau ne converge pas**\n"
        "üîß Solutions :\n"
        "   ‚Ä¢ Normalisez les donn√©es d'entr√©e\n"
        "   ‚Ä¢ R√©initialisez les poids (recr√©ez le r√©seau)\n"
        "   ‚Ä¢ V√©rifiez que le probl√®me est bien formul√©";
    
    conseils["Quelles sont les bonnes pratiques ?"] = 
        "Voici les meilleures pratiques pour utiliser NeuroUIT efficacement :\n\n"
        "**1. Commencez simple**\n"
        "   ‚úÖ Utilisez des architectures simples au d√©but\n"
        "   ‚úÖ Testez avec des datasets d'exemple\n"
        "   ‚úÖ Comprenez les bases avant de complexifier\n\n"
        "**2. Observez les m√©triques**\n"
        "   ‚úÖ Surveillez la courbe d'erreur pendant l'entra√Ænement\n"
        "   ‚úÖ Analysez les m√©triques apr√®s le test\n"
        "   ‚úÖ Utilisez la matrice de confusion pour comprendre les erreurs\n\n"
        "**3. Exp√©rimentez**\n"
        "   ‚úÖ Testez diff√©rentes architectures\n"
        "   ‚úÖ Variez les param√®tres d'entra√Ænement\n"
        "   ‚úÖ Comparez les r√©sultats\n\n"
        "**4. Pr√©paration des donn√©es**\n"
        "   ‚úÖ Normalisez vos donn√©es si n√©cessaire\n"
        "   ‚úÖ V√©rifiez la qualit√© du dataset\n"
        "   ‚úÖ Assurez-vous que le format CSV est correct\n\n"
        "**5. Documentation**\n"
        "   ‚úÖ Utilisez l'assistant IA pour comprendre les concepts\n"
        "   ‚úÖ Consultez les exemples de datasets fournis\n"
        "   ‚úÖ Lisez les messages d'erreur pour d√©boguer\n\n"
        "**6. It√©ration**\n"
        "   ‚úÖ Am√©liorez progressivement\n"
        "   ‚úÖ Documentez vos exp√©riences\n"
        "   ‚úÖ Apprenez de chaque tentative";
    
    knowledgeBase_["Conseils"] = conseils;
    
    // Remplir la liste des cat√©gories
    categoryList_->addItems(categories_);
    categoryList_->setCurrentRow(0);
}

void AIAssistantDialog::displayWelcomeMessage() {
    QString welcome = 
        "üßô Bienvenue dans l'Assistant IA de NeuroUIT !\n\n"
        "Je suis l√† pour vous aider √† comprendre les r√©seaux de neurones et √† utiliser cette application efficacement.\n\n"
        "üìö **Comment utiliser cet assistant :**\n"
        "1. S√©lectionnez une cat√©gorie dans la liste de gauche\n"
        "2. Choisissez une question qui vous int√©resse\n"
        "3. Lisez la r√©ponse d√©taill√©e √† droite\n\n"
        "üí° **Conseil :** Commencez par la cat√©gorie 'Introduction' si vous √™tes nouveau dans le domaine des r√©seaux de neurones.\n\n"
        "N'h√©sitez pas √† explorer toutes les cat√©gories pour une compr√©hension compl√®te !";
    
    answerDisplay_->setText(welcome);
    answerDisplay_->setStyleSheet(
        "QTextEdit { "
        "border: 2px solid #2196F3; "
        "border-radius: 5px; "
        "background-color: #E3F2FD; "
        "padding: 15px; "
        "font-size: 11pt; "
        "line-height: 1.6; "
        "}"
    );
}

void AIAssistantDialog::onCategoryChanged(int index) {
    if (index < 0 || index >= categories_.size()) return;
    
    QString category = categories_[index];
    questionList_->clear();
    
    if (knowledgeBase_.contains(category)) {
        const QMap<QString, QString>& questions = knowledgeBase_[category];
        QStringList questionList = questions.keys();
        questionList_->addItems(questionList);
    }
    
    // R√©afficher le message de bienvenue
    if (index == 0) {
        displayWelcomeMessage();
    } else {
        answerDisplay_->setText("S√©lectionnez une question dans la liste pour voir la r√©ponse d√©taill√©e.");
        answerDisplay_->setStyleSheet(
            "QTextEdit { "
            "border: 2px solid #BDBDBD; "
            "border-radius: 5px; "
            "background-color: #FFFFFF; "
            "padding: 15px; "
            "font-size: 11pt; "
            "line-height: 1.6; "
            "}"
        );
    }
}

void AIAssistantDialog::onQuestionSelected() {
    QListWidgetItem* item = questionList_->currentItem();
    if (!item) return;
    
    QString question = item->text();
    int categoryIndex = categoryList_->currentRow();
    
    if (categoryIndex < 0 || categoryIndex >= categories_.size()) return;
    
    QString category = categories_[categoryIndex];
    
    if (knowledgeBase_.contains(category) && knowledgeBase_[category].contains(question)) {
        QString answer = knowledgeBase_[category][question];
        displayAnswer(question, answer);
    }
}

void AIAssistantDialog::displayAnswer(const QString& question, const QString& answer) {
    QString formattedText = answer;
    
    // Convertir les marqueurs **texte** en <b>texte</b> de mani√®re simple
    int startPos = 0;
    while ((startPos = formattedText.indexOf("**", startPos)) != -1) {
        int endPos = formattedText.indexOf("**", startPos + 2);
        if (endPos != -1) {
            QString boldText = formattedText.mid(startPos + 2, endPos - startPos - 2);
            formattedText.replace(startPos, endPos - startPos + 2, "<b>" + boldText + "</b>");
            startPos += boldText.length() + 7; // Longueur de <b></b>
        } else {
            break;
        }
    }
    
    // Convertir les sauts de ligne
    formattedText.replace("\n\n", "<br><br>");
    formattedText.replace("\n", "<br>");
    
    // Encapsuler dans HTML
    QString html = QString(
        "<div style='margin-bottom: 15px;'>"
        "<h2 style='color: #2196F3; margin-bottom: 10px;'>%1</h2>"
        "</div>"
        "<div style='line-height: 1.8; color: #424242;'>"
        "%2"
        "</div>"
    ).arg(question.toHtmlEscaped(), formattedText);
    
    answerDisplay_->setHtml(html);
    answerDisplay_->setStyleSheet(
        "QTextEdit { "
        "border: 2px solid #4CAF50; "
        "border-radius: 5px; "
        "background-color: #FFFFFF; "
        "padding: 15px; "
        "font-size: 11pt; "
        "line-height: 1.6; "
        "}"
    );
}

